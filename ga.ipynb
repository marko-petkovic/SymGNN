{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from symgraph.model.model import GNN\n",
    "from symgraph.dataset import create_dataloaders\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from torch_geometric.data import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def si_al_ratio_to_al_proportion(ratio, n_atoms):\n",
    "    '''\n",
    "    Given a Si/Al ratio, return the proportion of Al atoms in the structure\n",
    "    '''\t\n",
    "    return n_atoms / (ratio + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_al_ratio_to_al_proportion(6.5, 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conversion factors:\n",
    "\n",
    "MFI, 0 Al: 0.1733675297\n",
    "MFI, 1 Al: 0.1727122100\n",
    "MFI, 2 Al: 0.1720618258\n",
    "MFI, 3 Al: 0.1714187342\n",
    "MFI, 4 Al: 0.1707756425\n",
    "\n",
    "MOR, 7 Al: 0.3292455306"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iso_model/MFI_SiAl95_Dunne.csv')\n",
    "\n",
    "p, q = df.values.T\n",
    "\n",
    "p_mfi_95 = 1000 * p # kpa to pa\n",
    "q_mfi_95 = q * y[1]\n",
    "\n",
    "df = pd.read_csv('iso_model/MFI_SiAl31_Dunne.csv')\n",
    "\n",
    "p, q = df.values.T\n",
    "\n",
    "p_mfi_31 = 1000 * p # kpa to pa\n",
    "q_mfi_31 = q * y[3]\n",
    "\n",
    "df = pd.read_csv('iso_model/MOR_SiAl5p8_Delgado.csv')\n",
    "\n",
    "p, q = df.values.T\n",
    "\n",
    "p_mor_5p8 = 1000 * p # kpa to pa\n",
    "q_mor_5p8 = q * 0.3292455306\n",
    "\n",
    "df = pd.read_csv('iso_model/MOR_SiAl6p5_Kwon.csv')\n",
    "\n",
    "p, q = df.values.T\n",
    "\n",
    "p_mor_6p5 = 1000 * p # kpa to pa\n",
    "q_mor_6p5 = q\n",
    "\n",
    "df = pd.read_csv('iso_model/LTA_SiAl_1_Parra.csv', delimiter=';', decimal=',')\n",
    "\n",
    "p, q = df.values.T\n",
    "\n",
    "p_lta_1 = 1000 * p # kpa to pa\n",
    "q_lta_1 = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(p_mfi_95, q_mfi_95, label='MFI Si/Al 95')\n",
    "plt.scatter(p_mfi_31, q_mfi_31, label='MFI Si/Al 31')\n",
    "plt.scatter(p_mor_5p8, q_mor_5p8, label='MOR Si/Al 5.8')\n",
    "plt.scatter(p_mor_6p5, q_mor_6p5, label='MOR Si/Al 6.5')\n",
    "plt.scatter(p_lta_1, q_lta_1, label='LTA Si/Al 1')\n",
    "plt.xlabel('Pressure (Pa)')\n",
    "plt.ylabel('Loading (mol/kg)')\n",
    "\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_in_mfi_95 = torch.log10(torch.tensor(p_mfi_95).unsqueeze(1))\n",
    "p_in_mfi_31 = torch.log10(torch.tensor(p_mfi_31).unsqueeze(1))\n",
    "p_in_mor_5p8 = torch.log10(torch.tensor(p_mor_5p8).unsqueeze(1))\n",
    "p_in_mor_6p5 = torch.log10(torch.tensor(p_mor_6p5).unsqueeze(1))\n",
    "p_in_lta_1 = torch.log10(torch.tensor(p_lta_1).unsqueeze(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.linspace(1, 7, 100).to('cuda').unsqueeze(-1)\n",
    "dp = p[1] - p[0]\n",
    "p_in = torch.cat([p, p[[-1]] + dp], dim=0) - dp/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spglib\n",
    "\n",
    "def lattice_params_to_vectors(a, b, c, alpha, beta, gamma):\n",
    "    \"\"\"\n",
    "    Convert lattice parameters (lengths and angles) into lattice vectors.\n",
    "    \n",
    "    Args:\n",
    "        a, b, c (float): Lattice lengths.\n",
    "        alpha, beta, gamma (float): Lattice angles in degrees.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: (3,3) array representing lattice vectors.\n",
    "    \"\"\"\n",
    "    # Convert angles to radians\n",
    "    alpha, beta, gamma = np.radians([alpha, beta, gamma])\n",
    "\n",
    "    # Compute lattice vectors\n",
    "    va = np.array([a, 0, 0])\n",
    "    vb = np.array([b * np.cos(gamma), b * np.sin(gamma), 0])\n",
    "    \n",
    "    vx = c * np.cos(beta)\n",
    "    vy = c * (np.cos(alpha) - np.cos(beta) * np.cos(gamma)) / np.sin(gamma)\n",
    "    vz = c * np.sqrt(1 - np.cos(beta)**2 - vy**2 / c**2)\n",
    "    \n",
    "    vc = np.array([vx, vy, vz])\n",
    "\n",
    "    return np.vstack([va, vb, vc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mor, *_= create_dataloaders(['MOR'], edge_type='radius', radius=8)\n",
    "tr_mfi, *_= create_dataloaders(['MFI'], edge_type='radius', radius=8)\n",
    "tr_lta, *_= create_dataloaders(['LTA'], edge_type='radius', radius=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symmetry_permutation_indices(lens, angs, positions):\n",
    "    \"\"\"\n",
    "    Compute index permutations due to symmetry for a given set of atomic positions.\n",
    "    \n",
    "    Args:\n",
    "        lattice_params (tuple): (a, b, c, alpha, beta, gamma).\n",
    "        positions (np.ndarray): (N, 3) array of fractional atomic positions.\n",
    "    \n",
    "    Returns:\n",
    "        list[np.ndarray]: List of index permutations corresponding to symmetry operations.\n",
    "    \"\"\"\n",
    "    # Convert lattice parameters to lattice vectors\n",
    "    lattice = lattice_params_to_vectors(*lens, *angs)\n",
    "\n",
    "    # Sort positions for consistency\n",
    "    sorted_indices = np.lexsort(positions.T)\n",
    "    positions = positions[sorted_indices]\n",
    "\n",
    "    # Define structure for Spglib (all atoms treated as identical)\n",
    "    num_atoms = len(positions)\n",
    "    dummy_types = np.zeros(num_atoms, dtype=int)\n",
    "    structure = (lattice, positions, dummy_types)\n",
    "\n",
    "    # Get symmetry operations\n",
    "    dataset = spglib.get_symmetry(structure, symprec=0.05)\n",
    "\n",
    "    # print(dataset)\n",
    "\n",
    "    index_permutations = []\n",
    "    for rotation, translation in zip(dataset['rotations'], dataset['translations']):\n",
    "        # Apply symmetry transformation\n",
    "        new_positions = np.dot(positions, rotation.T) + translation\n",
    "        new_positions = np.mod(new_positions, 1)  # Keep within unit cell\n",
    "\n",
    "        # Find permutation indices by matching transformed positions to original ones\n",
    "        permuted_indices = np.lexsort(new_positions.T)\n",
    "        index_permutations.append(permuted_indices)\n",
    "\n",
    "    index_permutations = np.array(index_permutations)\n",
    "    return index_permutations, positions\n",
    "\n",
    "def remove_duplicates_symmetrically(atoms, perms):\n",
    "    \n",
    "    atoms = torch.unique(atoms, dim=0)\n",
    "    \n",
    "    # print(atoms.shape)\n",
    "    \n",
    "    unique_atoms = None\n",
    "    # remove duplicates due to symmetry\n",
    "    for i in range(len(atoms)):\n",
    "        \n",
    "        if unique_atoms is None:\n",
    "            unique_atoms = atoms[i].unsqueeze(0)\n",
    "            continue\n",
    "        \n",
    "\n",
    "        perm_atom = atoms[i][perms]\n",
    "\n",
    "        # Check if any permuted version matches a unique atom\n",
    "        is_duplicate = (perm_atom.unsqueeze(1) == unique_atoms.unsqueeze(0)).all(dim=-1).any()\n",
    "\n",
    "        if is_duplicate:\n",
    "            # 2.5% chance to keep the configuration\n",
    "\n",
    "            remove_chance = 0.1 * min ( 0.075, (atoms[i].mean().item())) * 1/0.075\n",
    "\n",
    "            if np.random.uniform() < remove_chance:\n",
    "                is_duplicate = False\n",
    "\n",
    "        if not is_duplicate:\n",
    "            unique_atoms = torch.cat([unique_atoms, atoms[i].unsqueeze(0)], dim=0)\n",
    "\n",
    "    return unique_atoms\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mor_example = tr_mor.dataset[0]\n",
    "mfi_example = tr_mfi.dataset[0]\n",
    "lta_example = tr_lta.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mor_len = np.load('Data_numpy/MOR/lens.npy')\n",
    "mor_ang = np.load('Data_numpy/MOR/angs.npy')\n",
    "mor_pos = np.load('Data_numpy/MOR/pos.npy')\n",
    "\n",
    "mfi_len = np.load('Data_numpy/MFI/lens.npy')\n",
    "mfi_ang = np.load('Data_numpy/MFI/angs.npy')\n",
    "mfi_pos = np.load('Data_numpy/MFI/pos.npy')\n",
    "\n",
    "lta_len = np.load('Data_numpy/LTA/lens.npy')\n",
    "lta_ang = np.load('Data_numpy/LTA/angs.npy')\n",
    "lta_pos = np.load('Data_numpy/LTA/pos.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mor_perm, mor_pos = get_symmetry_permutation_indices(mor_len, mor_ang, mor_pos)\n",
    "mfi_perm, mfi_pos = get_symmetry_permutation_indices(mfi_len, mfi_ang, mfi_pos)\n",
    "lta_perm, lta_pos = get_symmetry_permutation_indices(lta_len, lta_ang, lta_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('bestmodel/sym_int/config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "model = GNN(**config['model']).cuda()\n",
    "model.load_state_dict(torch.load('bestmodel/sym_int/final.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp(x: torch.Tensor, xp: torch.Tensor, fp: torch.Tensor, dim: int=-1, extrapolate: str='constant') -> torch.Tensor:\n",
    "    \"\"\"One-dimensional linear interpolation between monotonically increasing sample\n",
    "    points, with extrapolation beyond sample points.\n",
    "\n",
    "    Returns the one-dimensional piecewise linear interpolant to a function with\n",
    "    given discrete data points :math:`(xp, fp)`, evaluated at :math:`x`.\n",
    "\n",
    "    Args:\n",
    "        x: The :math:`x`-coordinates at which to evaluate the interpolated\n",
    "            values.\n",
    "        xp: The :math:`x`-coordinates of the data points, must be increasing.\n",
    "        fp: The :math:`y`-coordinates of the data points, same shape as `xp`.\n",
    "        dim: Dimension across which to interpolate.\n",
    "        extrapolate: How to handle values outside the range of `xp`. Options are:\n",
    "            - 'linear': Extrapolate linearly beyond range of xp values.\n",
    "            - 'constant': Use the boundary value of `fp` for `x` values outside `xp`.\n",
    "\n",
    "    Returns:\n",
    "        The interpolated values, same size as `x`.\n",
    "    \"\"\"\n",
    "    # Move the interpolation dimension to the last axis\n",
    "    x = x.movedim(dim, -1)\n",
    "    xp = xp.movedim(dim, -1)\n",
    "    fp = fp.movedim(dim, -1)\n",
    "    \n",
    "    m = torch.diff(fp) / torch.diff(xp) # slope\n",
    "    b = fp[..., :-1] - m * xp[..., :-1] # offset\n",
    "    indices = torch.searchsorted(xp, x, right=False)\n",
    "    \n",
    "    if extrapolate == 'constant':\n",
    "        # Pad m and b to get constant values outside of xp range\n",
    "        m = torch.cat([torch.zeros_like(m)[..., :1], m, torch.zeros_like(m)[..., :1]], dim=-1)\n",
    "        b = torch.cat([fp[..., :1], b, fp[..., -1:]], dim=-1)\n",
    "    else: # extrapolate == 'linear'\n",
    "        indices = torch.clamp(indices - 1, 0, m.shape[-1] - 1)\n",
    "\n",
    "    values = m.gather(-1, indices) * x + b.gather(-1, indices)\n",
    "    \n",
    "    return values.movedim(-1, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "\n",
    "    def __init__(self, model):\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def run(self, pres, target_isotherm, example, perms, pop_size=100, generations=50, al_prop=0.2, top_n=10, elite_frac=0.15, zeo='RHO'):\n",
    "        \n",
    "        num_atoms = example.pos.shape[0]\n",
    "        # al_prop = si_al_ratio_to_al_proportion(si_al_ratio, num_atoms)\n",
    "\n",
    "        population = self.initialize_population(pop_size, num_atoms, al_prop)\n",
    "\n",
    "        # Evaluate population\n",
    "        isotherms = self.predict_isotherms_model(example, pres, population)\n",
    "        fitness = self.fitness(isotherms, target_isotherm, population, zeo)\n",
    "\n",
    "        for gen in range(generations):\n",
    "\n",
    "            \n",
    "            n_elite = int(elite_frac * pop_size)\n",
    "\n",
    "            sort_idx = torch.argsort(fitness, descending=True)\n",
    "            population = population[sort_idx]\n",
    "            fitness = fitness[sort_idx]\n",
    "\n",
    "            elite_pop = population[:n_elite]\n",
    "            mutate_pop = population[:2*n_elite]\n",
    "\n",
    "            # Mutate\n",
    "            mutated_pop = self.mutate(mutate_pop.clone())\n",
    "            scrambled_pop = self.scramble(mutate_pop.clone())\n",
    "\n",
    "            # change 1 Al to Si or vice versa\n",
    "            changed_pop = self.add_or_remove_al(elite_pop.clone())\n",
    "\n",
    "            new_pop = torch.cat([elite_pop, changed_pop, mutated_pop, scrambled_pop], dim=0)\n",
    "\n",
    "            # remove duplicates\n",
    "            unique_pop = remove_duplicates_symmetrically(new_pop, perms)\n",
    "            # unique_pop = new_pop\n",
    "\n",
    "            n_missing = pop_size - len(unique_pop)\n",
    "\n",
    "            if n_missing > 0:\n",
    "                new_pop = self.initialize_population(n_missing, num_atoms, al_prop) # np.random.rand()*al_prop)\n",
    "                unique_pop = torch.cat([unique_pop, new_pop], dim=0)\n",
    "            \n",
    "            population = unique_pop\n",
    "\n",
    "            # Evaluate population\n",
    "            isotherms = self.predict_isotherms_model(example, pres, population)\n",
    "            fitness = self.fitness(isotherms, target_isotherm, population, zeo)\n",
    "\n",
    "            print(f'Generation {gen}: Best fitness: {fitness.max()}')\n",
    "\n",
    "            # population = population[torch.argsort(fitness, descending=True)]\n",
    "\n",
    "        return population[:top_n]\n",
    "    \n",
    "    def add_or_remove_al(self, population):\n",
    "        population = population.clone()\n",
    "\n",
    "        for i in range(len(population)):\n",
    "            # find Al and change to Si\n",
    "            if sum(population[i]) > 0 and np.random.rand() < 0.6:\n",
    "                al_idx = torch.where(population[i] == 1)[0]\n",
    "                # pick one Al to change to Si\n",
    "                idx = np.random.choice(al_idx.cpu())\n",
    "                \n",
    "                population[i][idx] = 0\n",
    "            else:\n",
    "                si_idx = torch.where(population[i] == 0)[0]\n",
    "                # pick one Si to change to Al\n",
    "                idx = np.random.choice(si_idx.cpu())\n",
    "                population[i][idx] = 1\n",
    "\n",
    "        return population\n",
    "\n",
    "    \n",
    "    def mutate(self, population, min_mutations=1, max_mutations=0.05):\n",
    "        max_mutations = max(int(max_mutations * len(population[0])), 2)\n",
    "        population = population.clone()\n",
    "        for i in range(len(population)): \n",
    "            n_mutations = np.random.randint(min_mutations, max_mutations)\n",
    "            swap_indices = torch.randperm(len(population[i]))[:n_mutations]  # Pick two sites to swap\n",
    "            population[i][swap_indices] = 1 - population[i][swap_indices]\n",
    "\n",
    "        return population\n",
    "\n",
    "    def scramble(self, population):\n",
    "        population = population.clone()\n",
    "        for i in range(len(population)):\n",
    "            indices = torch.randperm(len(population[i]))\n",
    "            population[i] = population[i][indices]\n",
    "\n",
    "        return population\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def predict_isotherms_model(self, example, pres, population):\n",
    "        self.model.eval()\n",
    "        data_list = []\n",
    "        for i in range(len(population)):\n",
    "            data = example.clone()\n",
    "            data.x = population[i].unsqueeze(1).float()\n",
    "            data_list.append(data)\n",
    "        \n",
    "        data =  Batch.from_data_list(data_list).to('cuda')\n",
    "        _, q_prime = self.model(data, p_in)\n",
    "        q = torch.cumulative_trapezoid(q_prime, p_in.squeeze(-1), dim=1)\n",
    "        q_pred = interp(pres[None].squeeze(-1).repeat(q.shape[0],1), p[None].squeeze(-1).repeat(q.shape[0], 1), q)\n",
    "        # select every other element\n",
    "        return q_pred\n",
    "    \n",
    "    def fitness(self, isotherms, target_isotherm, population, zeo='RHO'):\n",
    "        \n",
    "        # percentage_error = (isotherms - target_isotherm) / (target_isotherm + 1e-3)\n",
    "\n",
    "        scale = target_isotherm / isotherms\n",
    "\n",
    "        if zeo in ['RHO', 'LTA', 'FAU']:\n",
    "            max_clamp = 5\n",
    "            scale = scale.clamp(1, 6)\n",
    "        else:\n",
    "            \n",
    "            scale = scale.clamp(max = 1.5)\n",
    "            max_clamp = 1.3\n",
    "\n",
    "        scale = scale.mean(dim=1).unsqueeze(1)\n",
    "        scale = torch.clamp(scale, 1, max_clamp)\n",
    "\n",
    "        scaled_isotherms = isotherms * scale\n",
    "\n",
    "        err = isotherms - target_isotherm\n",
    "        scaled_err = scaled_isotherms - target_isotherm\n",
    "\n",
    "        mae = torch.mean(err.abs(), dim=1)\n",
    "        scaled_mae = torch.mean(scaled_err.abs(), dim=1)\n",
    "\n",
    "        # return -scaled_mae - 0.02 * mae - 8 * (population.mean(dim=-1)**2).clamp(max=0.035)\n",
    "\n",
    "        mean_pop = population.mean(dim=-1).clamp(min=0, max=0.35)\n",
    "        al_pen = torch.where(mean_pop < 0.25, 2.83 * mean_pop, (0.25*2.83)+0.05*mean_pop)\n",
    "        return -scaled_mae - 0.02 * mae - al_pen\n",
    "\n",
    "    \n",
    "    def initialize_population(self, population_size, num_atoms, al_prop):\n",
    "        pop = torch.bernoulli(torch.ones(population_size, num_atoms) * al_prop).cuda()\n",
    "        return pop\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop, top_n = 200, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mfi_95 = ga.run(p_in_mfi_95.cuda().float(), torch.tensor(q_mfi_95).float().cuda(), mfi_example, torch.tensor(mfi_perm), al_prop=0.05, elite_frac=0.125, pop_size=pop, top_n=top_n, zeo='MFI')\n",
    "best_mfi_31 = ga.run(p_in_mfi_31.cuda().float(), torch.tensor(q_mfi_31).float().cuda(), mfi_example, torch.tensor(mfi_perm), al_prop=0.05, elite_frac=0.125, pop_size=pop, top_n=top_n, zeo='MFI')\n",
    "best_mor_5p8 = ga.run(p_in_mor_5p8.cuda().float()[3:], torch.tensor(q_mor_5p8).float().cuda()[3:], mor_example, torch.tensor(mor_perm), al_prop=0.05, elite_frac=0.125, pop_size=pop, top_n=top_n, zeo='MOR')\n",
    "best_mor_6p5 = ga.run(p_in_mor_6p5.cuda().float(), torch.tensor(q_mor_6p5).float().cuda(), mor_example, torch.tensor(mor_perm), al_prop=0.05, elite_frac=0.125, pop_size=pop, top_n=top_n, zeo='MOR')\n",
    "best_lta_1 = ga.run(p_in_lta_1.cuda().float(), torch.tensor(q_lta_1).float().cuda(), lta_example, torch.tensor(lta_perm), al_prop=0.75, elite_frac=0.125, pop_size=pop, top_n=top_n, zeo='LTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ga_results/best_mfi_95.npy', best_mfi_95.cpu().numpy())\n",
    "np.save('ga_results/best_mfi_31.npy', best_mfi_31.cpu().numpy())\n",
    "np.save('ga_results/best_mor_5p8.npy', best_mor_5p8.cpu().numpy())\n",
    "np.save('ga_results/best_mor_6p5.npy', best_mor_6p5.cpu().numpy())\n",
    "np.save('ga_results/best_lta_1.npy', best_lta_1.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data(population, example):\n",
    "    data_list = []\n",
    "    for i in range(len(population)):\n",
    "        data = example.clone()\n",
    "        data.x = population[i].unsqueeze(1).float(\n",
    "            \n",
    "        )\n",
    "        \n",
    "        data_list.append(data)\n",
    "    \n",
    "    return Batch.from_data_list(data_list).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "# for each amount of Al, calculate the number of structures\n",
    "n_al = torch.sum(best_mfi_95, dim=1)\n",
    "n_al = torch.unique(n_al, return_counts=True)\n",
    "ax[0].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "ax[0].set_title('MFI Si/Al 95')\n",
    "\n",
    "n_al = torch.sum(best_mfi_31, dim=1)\n",
    "n_al = torch.unique(n_al, return_counts=True)\n",
    "ax[1].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "ax[1].set_title('MFI Si/Al 31')\n",
    "\n",
    "n_al = torch.sum(best_mor_5p8, dim=1)\n",
    "n_al = torch.unique(n_al, return_counts=True)\n",
    "ax[2].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "ax[2].set_title('MOR Si/Al 5.8')\n",
    "\n",
    "n_al = torch.sum(best_mor_6p5, dim=1)\n",
    "n_al = torch.unique(n_al, return_counts=True)\n",
    "ax[3].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "ax[3].set_title('MOR Si/Al 6.5')\n",
    "\n",
    "# n_al = torch.sum(best_rho_3p4, dim=1)\n",
    "# n_al = torch.unique(n_al, return_counts=True)\n",
    "# ax[4].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "# ax[4].set_title('RHO Si/Al 3.4')\n",
    "\n",
    "n_al = torch.sum(best_lta_1, dim=1)\n",
    "n_al = torch.unique(n_al, return_counts=True)\n",
    "ax[4].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "ax[4].set_title('LTA Si/Al 1')\n",
    "\n",
    "# n_al = torch.sum(best_fau_1, dim=1) \n",
    "# n_al = torch.unique(n_al, return_counts=True)\n",
    "# ax[6].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "# ax[6].set_title('FAU Si/Al 1')\n",
    "\n",
    "# n_al = torch.sum(best_mfi, dim=1)\n",
    "# n_al = torch.unique(n_al, return_counts=True)\n",
    "# ax[7].bar(n_al[0].cpu(), n_al[1].cpu(), width=1)\n",
    "# ax[7].set_title('MFI Pure Si')\n",
    "\n",
    "ax[0].vlines(1, 0, 20, color='r', linestyle='--')\n",
    "ax[1].vlines(3, 0, 20, color='r', linestyle='--')\n",
    "ax[2].vlines(7, 0, 20, color='r', linestyle='--')\n",
    "ax[3].vlines(6.4, 0, 20, color='r', linestyle='--')\n",
    "# ax[4].vlines(11, 0, 20, color='r', linestyle='--')\n",
    "ax[4].vlines(12, 0, 20, color='r', linestyle='--')\n",
    "# ax[6].vlines(48, 0, 20, color='r', linestyle='--')\n",
    "# ax[7].vlines(0, 0, 20, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
